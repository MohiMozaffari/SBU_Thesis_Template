@article{Khadiev2019a,
abstract = {Energy field plays an important role in commercial world and makes a vital part of humanity. The paper considers the prediction problem concerning spent electrical energy in the Republic of Tatarstan, Russia. In fact, the task of electrical load prediction was set for each hour of the specified period. We solve the problem using Machine learning methods. Four models are considered. These are Linear Regression, Decision Tree, Random Forest and Gradient Tree Boosting. Linear Regression method shows good results, the average relative error is 3.98%. Decision Tree and Random Forest show the worst result, the average relative error is 10.44%. Gradient Tree Boosting show the best result, the average relative error made 2.17%. At the same time, Linear Regression model is much faster than other ones and more useful in industry. In the paper we show that using several techniques we can improve results for Linear Regression, such that it will be close to another advanced algorithms. The average relative error that is less than 5% is considered as a high enough result. The solution of the problem with a small error allows us to prevent the accidents related to electric overload. We assume that load depends on date, time and temperature. Then input variable models were obtained from these data. It is common approach to use that parameters as input data but let us note that the results obtained by other researchers are not suitable for this area, since each area has individual climatic, geological and social features.},
author = {Khadiev, K. R. and Safina, L. I.},
doi = {10.1088/1742-6596/1352/1/012027},
issn = {17426596},
journal = {Journal of Physics: Conference Series},
month = {oct},
number = {1},
pages = {012027},
title = {{On linear regression and other advanced algorithms for electrical load forecast using weather and time data}},
url = {https://iopscience.iop.org/article/10.1088/1742-6596/1352/1/012027},
volume = {1352},
year = {2019}
}

@article{Kumar2017a,
abstract = {A proper initialization of the weights in a neural network is critical to its convergence. Current insights into weight initialization come primarily from linear activation functions. In this paper, I develop a theory for weight initializations with non-linear activations. First, I derive a general weight initialization strategy for any neural network using activation functions differentiable at 0. Next, I derive the weight initialization strategy for the Rectified Linear Unit (RELU), and provide theoretical insights into why the Xavier initialization is a poor choice with RELU activations. My analysis provides a clear demonstration of the role of non-linearities in determining the proper weight initializations.},
archivePrefix = {arXiv},
arxivId = {1704.08863},
author = {Kumar, Siddharth Krishna},
eprint = {1704.08863},
issn = {23318422},
journal = {arXiv},
pages = {1--9},
title = {{On weight initialization in deep neural networks}},
year = {2017}
}
